{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5003c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import logging\n",
    "import os\n",
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "import torch\n",
    "import wandb\n",
    "from fvcore.common.checkpoint import Checkpointer, PeriodicCheckpointer\n",
    "from torch.cuda import amp\n",
    "from torch.nn import SyncBatchNorm\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import detectron2.utils.comm as d2_comm\n",
    "from detectron2.data.catalog import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.evaluation import DatasetEvaluators, inference_on_dataset\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.solver import build_lr_scheduler, build_optimizer\n",
    "from detectron2.utils.events import CommonMetricPrinter, get_event_storage\n",
    "\n",
    "from tridet.modeling.dd3d import dense_depth\n",
    "import tridet.modeling  # pylint: disable=unused-import\n",
    "import tridet.utils.comm as comm\n",
    "from tridet.data import build_test_dataloader, build_train_dataloader\n",
    "from tridet.data.dataset_mappers import get_dataset_mapper\n",
    "from tridet.data.datasets import random_sample_dataset_dicts, register_datasets\n",
    "from tridet.evaluators import get_evaluator\n",
    "from tridet.modeling import build_tta_model\n",
    "from tridet.utils.s3 import sync_output_dir_s3\n",
    "from tridet.utils.setup import setup\n",
    "from tridet.utils.train import get_inference_output_dir, print_test_results\n",
    "from tridet.utils.visualization import mosaic, save_vis\n",
    "from tridet.utils.wandb import flatten_dict, log_nested_dict\n",
    "from tridet.visualizers import get_dataloader_visualizer, get_predictions_visualizer\n",
    "\n",
    "# from tridet.data.datasets.kitti_3d import register_kitti_3d_datasets\n",
    "from tridet.data.datasets.custom import register_kitti_3d_datasets\n",
    "from tridet.data.datasets.nuscenes import register_nuscenes_datasets\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from kluster import Kluster\n",
    "from panoramator import Projection, Panoramator, mongo_to_shards\n",
    "from detectron2.data.common import AspectRatioGroupedDataset, DatasetFromList, MapDataset\n",
    "from tridet.data.augmentations import build_augmentation\n",
    "from tridet.utils.tasks import TaskManager\n",
    "import numpy as np\n",
    "from tridet.structures.pose import Pose\n",
    "from typing import List, Union\n",
    "from detectron2.config import configurable\n",
    "from detectron2.data import transforms as T\n",
    "from tridet.evaluators.kitti_3d_evaluator import convert_3d_box_to_kitti\n",
    "from tridet.utils.geometry import project_points3d\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d2d50af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panoramator structures\n",
    "\n",
    "class PanoramaDataset(Dataset):\n",
    "\n",
    "    def __init__(self, mongo_args, segments, keyword, projections):\n",
    "        kluster = Kluster(session=MongoClient(*mongo_args))\n",
    "        segments = kluster.fetch_data(\n",
    "            \"segments\",\n",
    "            {\"_id\": {\"$in\": segments}, \"street_view\": {\"$elemMatch\": {\"available\": True, keyword: {\"$exists\": False}}}}\n",
    "        )\n",
    "        self.kluster = mongo_args\n",
    "        lines = [\n",
    "            (segment[\"_id\"], i, line[\"panoramas\"])\n",
    "            for segment in segments for i, line in enumerate(segment[\"street_view\"])\n",
    "            if \"available\" in line and keyword not in line\n",
    "        ]\n",
    "        self.panoramas = [(sid, lidx, pidx, panorama)\n",
    "                          for sid, lidx, panoramas in lines for pidx, panorama in enumerate(panoramas)]\n",
    "        self.projections = projections\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.panoramas)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if type(self.kluster) == tuple:\n",
    "            self.kluster = Kluster(session=MongoClient(*self.kluster))\n",
    "        segment_id, line_idx, panorama_idx, panorama_id = self.panoramas[idx]\n",
    "        panorama = main_kluster.kluster[\"street_view\"].find_one({\"_id\": panorama_id})\n",
    "        shards = mongo_to_shards(panorama[\"image_shards\"])\n",
    "        panoramator = Panoramator(shards=shards, atomic_resolution=panorama[\"resolution\"][0]//16)\n",
    "        panoramator.build_state()\n",
    "        projections = [(projection_meta, panoramator.get_projection(projection_meta))\n",
    "                       for projection_meta in self.projections]\n",
    "        return segment_id, line_idx, panorama_id, projections\n",
    "\n",
    "    \n",
    "def inference(kluster, predictor, data_loader, keyword):\n",
    "    current_line = None\n",
    "    line_count = 0\n",
    "\n",
    "    for i, (segment_id, line_idx, panorama_id, projections) in enumerate(data_loader):\n",
    "        itime = time.time()\n",
    "\n",
    "        if current_line is not None and current_line != (segment_id, line_idx):\n",
    "            sid, lidx = current_line\n",
    "            # kluster.kluster[\"segments\"].update_one({\"_id\": sid}, {\"$set\": {f\"street_view.{lidx}.{keyword}\": True}})\n",
    "            line_count += 1\n",
    "            print(f\"Finished line {line_count}! (Segment:{sid};Index:{lidx})\")\n",
    "        current_line = (segment_id, line_idx)\n",
    "\n",
    "        result = []\n",
    "        for projection_meta, projection in projections:\n",
    "            predictions = predictor(projection)\n",
    "            result.append({\"projection\": projection_meta.get_dict(), **predictions})\n",
    "        # kluster.kluster[\"street_view\"].update_one({\"_id\": panorama_id}, {\"$set\": {keyword: result}})\n",
    "\n",
    "        print(f\"Predicted panorama {i+1}/{len(data_loader)} (Time elapsed: {time.time()-itime:.2f}s) ({panorama_id})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e447627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DD3D structures\n",
    "\n",
    "class ParkinkDatasetMapper:\n",
    "    \n",
    "    @configurable\n",
    "    def __init__(self, is_train: bool, task_manager, augmentations: List[Union[T.Augmentation, T.Transform]], \n",
    "                 image_format: str, intrinsics: list, extrinsics: dict):\n",
    "        self.is_train = is_train\n",
    "        self.task_manager = task_manager\n",
    "        self.augmentations = T.AugmentationList(augmentations)\n",
    "        print(\"Augmentations used: \" + str(augmentations))\n",
    "        self.image_format = image_format\n",
    "        self.intrinsics = intrinsics\n",
    "        self.extrinsics = extrinsics\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, cfg, is_train, intrinsics, extrinsics):\n",
    "        augs = build_augmentation(cfg, is_train)\n",
    "        tm = TaskManager(cfg)\n",
    "        return {\"is_train\": is_train, \"task_manager\": tm, \"augmentations\": augs, \"image_format\": cfg.INPUT.FORMAT, \n",
    "               \"intrinsics\": intrinsics, \"extrinsics\": extrinsics}\n",
    "\n",
    "    def __call__(self, parkink_data):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset_dict (dict): Metadata of one image, in Detectron2 Dataset format.\n",
    "        Returns:\n",
    "            dict: a format that builtin models in detectron2 accept\n",
    "        \"\"\"\n",
    "        segment_id, line_idx, panorama_id, projections = parkink_data\n",
    "        \n",
    "        kitti_projections = []\n",
    "        for projection_meta, image in projections:\n",
    "            kitti = {\"width\": image.shape[1], \"height\": image.shape[0],\n",
    "                     \"intrinsics\": self.intrinsics, \"extrinsics\": self.extrinsics}\n",
    "            \n",
    "            if type(image) == torch.Tensor:  # When using a DataLoader, Tensors instead of arrays will be given\n",
    "                image = image.numpy()\n",
    "            image = image[:, :, ::-1]  # VERY IMPORTANT! CONVERT IMAGE FROM RGB (PIL format) TO BGR (model format)\n",
    "            aug_input = T.AugInput(image)\n",
    "            transforms = self.augmentations(aug_input)\n",
    "            image = aug_input.image\n",
    "            kitti[\"image\"] = torch.as_tensor(np.ascontiguousarray(image.transpose(2, 0, 1)))\n",
    "            \n",
    "            intrinsics = np.reshape(kitti[\"intrinsics\"], (3, 3)).astype(np.float32)\n",
    "            intrinsics = transforms.apply_intrinsics(intrinsics)\n",
    "            kitti[\"intrinsics\"] = torch.as_tensor(intrinsics)\n",
    "            kitti[\"inv_intrinsics\"] = torch.as_tensor(np.linalg.inv(intrinsics))\n",
    "            \n",
    "            extrinsics = Pose(wxyz=np.float32(kitti[\"extrinsics\"][\"wxyz\"]),\n",
    "                              tvec=np.float32(kitti[\"extrinsics\"][\"tvec\"]))\n",
    "            kitti[\"extrinsics\"] = extrinsics\n",
    "            \n",
    "            kitti_projections.append((projection_meta, kitti))\n",
    "            \n",
    "        return segment_id, line_idx, panorama_id, kitti_projections\n",
    "\n",
    "\n",
    "def meter_to_angle(x, y, z):\n",
    "    # Convert meters coordinates to horizontal and vertical angles.\n",
    "    # We negate the vertical and so that up is positive and down is negative.\n",
    "    return np.array([np.arctan2(x, z), -np.arctan2(y, z)]) / np.pi * 180\n",
    "\n",
    "s_count = s_confidence = 0\n",
    "\n",
    "def process_scene(model, input_dict, plot=False, log=False):\n",
    "    global s_confidence, s_count\n",
    "    CLASS_MAPPER = (\"Car\", \"Pedestrian\", \"Cyclist\", \"Van\", \"Truck\")\n",
    "    THRESHOLD = 0.5\n",
    "    with torch.no_grad():\n",
    "        raw_output = model([input_dict])[0] #raw_output = model([input_dict])\n",
    "    #print(raw_output)\n",
    "    plt.rcParams['figure.figsize'] = [15, 15]\n",
    "    \n",
    "    instances = raw_output[\"instances\"].get_fields()\n",
    "    \n",
    "    # We discard \n",
    "    # - instances[\"scores\"]: scores_3d gives a more informed score, taking into account the 3d box\n",
    "    # - instances[\"locations\"]: this is ~= object center, but the center given by 3d box is more accurate\n",
    "    # - instances[\"pred_boxes\"]: 2d boxes, a priori useless if we have 3d ones (is this an intermediate step?)\n",
    "    # - instances[\"fpn_levels\"]: This is related to at which level of the net the object is detected... useless\n",
    "    zipped = zip(instances[\"scores_3d\"], instances[\"pred_classes\"], instances[\"pred_boxes3d\"])\n",
    "    subd = {\"pixels\": [], \"meters\": [], \"degrees\": []}\n",
    "    prediction = {\"score\": [], \"kitti_class\": [], \"size\": [], \"orientation\": [], \"center\": deepcopy(subd),\n",
    "                  \"front_upper_left\": deepcopy(subd), \"front_upper_right\": deepcopy(subd),\n",
    "                  \"front_lower_right\": deepcopy(subd), \"front_lower_left\": deepcopy(subd),\n",
    "                  \"back_upper_left\": deepcopy(subd), \"back_upper_right\": deepcopy(subd),\n",
    "                  \"back_lower_right\": deepcopy(subd), \"back_lower_left\": deepcopy(subd)}\n",
    "    for score_3d, kitti_class, box_3d in zipped:\n",
    "        if score_3d < THRESHOLD:  # If the model is not confident enough, we skip the prediction\n",
    "            continue\n",
    "        s_confidence = (s_confidence * s_count + score_3d.item()) / (s_count + 1)\n",
    "        s_count += 1\n",
    "        print(round(s_confidence, 3), s_count)\n",
    "        \n",
    "        prediction[\"score\"].append(round(score_3d.item(), 3))\n",
    "        if kitti_class not in (0, 3, 4):  # If the detected object is not a car, van or truck, we skip it\n",
    "            continue\n",
    "        kitti_class = CLASS_MAPPER[kitti_class]\n",
    "        prediction[\"kitti_class\"].append(kitti_class)\n",
    "        \n",
    "        center_pix = box_3d.proj_ctr[0].cpu().numpy()  # width (x), height (y)\n",
    "        center_met = box_3d.tvec[0].cpu().numpy()  # horizontal (left->right), vertical (up->down), depth (back->front)\n",
    "        center_ang = meter_to_angle(*center_met)  # horizontal (left->right, degrees), vertical (down->up, degrees)\n",
    "        prediction[\"center\"][\"pixels\"].append([round(e, 1) for e in center_pix.tolist()])\n",
    "        prediction[\"center\"][\"meters\"].append([round(e, 2) for e in center_met.tolist()])\n",
    "        prediction[\"center\"][\"degrees\"].append([round(e, 2) for e in center_ang.tolist()])\n",
    "        \n",
    "        size = box_3d.size[0].cpu().numpy()  # width, length, height (meters)\n",
    "        prediction[\"size\"].append([round(e, 2) for e in size.tolist()])\n",
    "        \n",
    "        floor_met = center_met + np.array([0, size[2]/2, 0])\n",
    "        floor_ang = meter_to_angle(*floor_met)\n",
    "        floor_pix = project_points3d(np.array([floor_met]), input_dict[\"intrinsics\"].numpy())\n",
    "        print(\"floor\", floor_pix)\n",
    "        print(\"center\", center_pix)\n",
    "        \n",
    "        corners_met = box_3d.corners[0].cpu().numpy()\n",
    "        corners_ang = np.array([meter_to_angle(*corner) for corner in corners_met])\n",
    "        corners_pix = project_points3d(corners_met, input_dict[\"intrinsics\"].numpy())\n",
    "        corners_pix = [pix * (-1 if met[2] < 0 else 1) for met, pix in zip(corners_met, corners_pix)]\n",
    "        keys = [\"front_upper_left\", \"front_upper_right\", \"front_lower_right\", \"front_lower_left\", \n",
    "                \"back_upper_left\", \"back_upper_right\", \"back_lower_right\", \"back_lower_left\"]\n",
    "        for key, pix, met, ang in zip(keys, corners_pix, corners_met, corners_ang):\n",
    "            prediction[key][\"pixels\"].append([round(e, 1) for e in pix.tolist()])\n",
    "            prediction[key][\"meters\"].append([round(e, 2) for e in met.tolist()])\n",
    "            prediction[key][\"degrees\"].append([round(e, 2) for e in ang.tolist()])\n",
    "        \n",
    "        w, l, h, x, y, z, roty, alpha = convert_3d_box_to_kitti(box_3d)\n",
    "        orientation = - alpha / np.pi * 180  # The alpha in angles.png, clockwise is positive (180 to -180 range) (90 means we see car back) (-90 means we see car front)        prediction[\"orientation\"].append(round(orientation, 2))\n",
    "        print(\"orientation\", orientation)\n",
    "        \n",
    "        if log:\n",
    "            print(f\"Confidence: {score_3d}\")\n",
    "            print(f\"Class: {kitti_class}\")\n",
    "            print(f\"Center (pixels): {center_pix}\")\n",
    "            print(f\"Center (meters): {center_met}\")\n",
    "            print(f\"Center (degrees): {center_ang}\")\n",
    "            print(f\"Size (meters): {size}\")\n",
    "            print(f\"Corners (pixels): {corners_pix}\")\n",
    "            print(f\"Corners (meters): {corners_met}\")\n",
    "            print(f\"Corners (degrees): {corners_ang}\")\n",
    "            print(f\"Car Orientation (degrees): {orientation}\")\n",
    "        \n",
    "        if plot:\n",
    "            for a, b, c, d in [(0, 1, 2, 3), (4, 5, 6, 7), (0, 4, 7, 3), (1, 5, 6, 2), (0, 2, 1, 3)]:\n",
    "                coord = [corners_pix[a], corners_pix[b], corners_pix[c], corners_pix[d], corners_pix[a]] \n",
    "                xs, ys = zip(*coord)\n",
    "                plt.plot(xs, ys, color='r')\n",
    "    \n",
    "    if plot:\n",
    "        img = input_dict[\"image\"].cpu().numpy().transpose(1, 2, 0)[:, :, ::-1]\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "    \"\"\"\n",
    "    LEVELS = 1\n",
    "    \n",
    "    if plot:\n",
    "        plt.rcParams['figure.figsize'] = [9, 4.5*(LEVELS+1)]#[9, 4.5]\n",
    "        fig, axes = plt.subplots(LEVELS+1, 1)\n",
    "        img = input_dict[\"image\"].cpu().numpy().transpose(1, 2, 0)[:, :, ::-1]\n",
    "        axes[0].imshow(img)\n",
    "        #plt.imshow(img)\n",
    "        #plt.show()\n",
    "\n",
    "        for i, element in enumerate(raw_output[:LEVELS]):\n",
    "            axes[i+1].imshow(element.squeeze().cpu().numpy(), cmap=cm.get_cmap(\"plasma\")) # \"plasma_r\"\n",
    "            #plt.imshow(element.squeeze().cpu().numpy(), cmap=\"plasma\")\n",
    "            #plt.show()\n",
    "            #print(element.shape)\n",
    "        #print(raw_output)\n",
    "    \n",
    "    #from pprint import pprint\n",
    "    #pprint(prediction)\n",
    "    \"\"\"\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b42a369",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG_PATH = \"../configs/\"\n",
    "CFG_NAME = \"kitti99_defaults\"\n",
    "CHECKPOINT = \"../models/kitti_v99.pth\"#\"../models/depth_pretrained_v99.pth\"\n",
    "# VERY IMPORTANT!!! https://stackoverflow.com/questions/39992968/how-to-calculate-field-of-view-of-the-camera-from-camera-intrinsic-matrix\n",
    "#INTRINSICSDD3D = [612.6, 0.0, 640.0, 0.0, 612.6, 128.0, 0.0, 0.0, 1.0]\n",
    "INTRINSICS = [707, 0.0, 640.0, 0.0, 707, 128.0, 0.0, 0.0, 1.0]\n",
    "INTRINSICS = [728.5, 0.0, 640.0, 0.0, 728.5, 192.0, 0.0, 0.0, 1.0]\n",
    "INTRINSICS = [622.2, 0.0, 640.0, 0.0, 622.2, 192.0, 0.0, 0.0, 1.0]\n",
    "INTRINSICS = [728.5, 0.0, 640.0, 0.0, 546.7, 192.0, 0.0, 0.0, 1.0]\n",
    "INTRINSICS = [728.5, 0.0, 640.0, 0.0, 728.5, 112.0, 0.0, 0.0, 1.0]\n",
    "#INTRINSICS = [728.5, 0.0, 640.0, 0.0, 728.5, 104.0, 0.0, 0.0, 1.0]\n",
    "EXTRINSICS = {\"wxyz\": [1.0, 0.0, 0.0, 0.0], \"tvec\": [0.0, 0.0, 0.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc2233ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGO_SESSION_ARGS = (\"localhost\", 27017)\n",
    "PREDICTION_KEYWORD = \"kitti_cars\"\n",
    "TIMEOUT = 180\n",
    "\"\"\"\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=0, fov_horizontal=92.5, fov_vertical=45.36,\n",
    "                          full_resolution_x=1280, full_resolution_y=512,\n",
    "                          offset_x=0, offset_y=512-384, resolution_x=1280, resolution_y=384),\n",
    "               Projection(center_horizontal=180, center_vertical=0, fov_horizontal=92.5, fov_vertical=45.36,\n",
    "                          full_resolution_x=1280, full_resolution_y=512,\n",
    "                          offset_x=0, offset_y=512-384, resolution_x=1280, resolution_y=384)]\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=0, fov_horizontal=60, fov_vertical=49.58,\n",
    "                          full_resolution_x=640, full_resolution_y=512,\n",
    "                          offset_x=0, offset_y=512-384, resolution_x=640, resolution_y=384)]\n",
    "\"\"\"\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=0, fov_horizontal=82.6, fov_vertical=38.7,\n",
    "                          full_resolution_x=1280, full_resolution_y=512,\n",
    "                          offset_x=0, offset_y=512-384, resolution_x=1280, resolution_y=384),\n",
    "               Projection(center_horizontal=180, center_vertical=0, fov_horizontal=82.6, fov_vertical=38.7,\n",
    "                          full_resolution_x=1280, full_resolution_y=512,\n",
    "                          offset_x=0, offset_y=512-384, resolution_x=1280, resolution_y=384)]\n",
    "\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=0, fov_horizontal=82.6, fov_vertical=47.5,\n",
    "                          full_resolution_x=1280, full_resolution_y=640,\n",
    "                          offset_x=0, offset_y=640-384, resolution_x=1280, resolution_y=384),\n",
    "               Projection(center_horizontal=180, center_vertical=0, fov_horizontal=82.6, fov_vertical=47.5,\n",
    "                          full_resolution_x=1280, full_resolution_y=640,\n",
    "                          offset_x=0, offset_y=640-384, resolution_x=1280, resolution_y=384)]\n",
    "\"\"\"\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=0, fov_horizontal=82.6, fov_vertical=29.6,\n",
    "                          full_resolution_x=1280, full_resolution_y=384,\n",
    "                          offset_x=0, offset_y=0, resolution_x=1280, resolution_y=384),\n",
    "               Projection(center_horizontal=180, center_vertical=0, fov_horizontal=82.6, fov_vertical=29.6,\n",
    "                          full_resolution_x=1280, full_resolution_y=384,\n",
    "                          offset_x=0, offset_y=0, resolution_x=1280, resolution_y=384)]\n",
    "\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=0, fov_horizontal=82.6, fov_vertical=47.4,\n",
    "                          full_resolution_x=1280, full_resolution_y=640,\n",
    "                          offset_x=0, offset_y=640-384, resolution_x=1280, resolution_y=384),\n",
    "               Projection(center_horizontal=180, center_vertical=0, fov_horizontal=82.6, fov_vertical=47.4,\n",
    "                          full_resolution_x=1280, full_resolution_y=640,\n",
    "                          offset_x=0, offset_y=640-384, resolution_x=1280, resolution_y=384)]\n",
    "\n",
    "                          offset_x=0, offset_y=0, resolution_x=1280, resolution_y=384)]\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=0, fov_horizontal=82.6, fov_vertical=38.7,\n",
    "                          full_resolution_x=1280, full_resolution_y=512,\n",
    "                          offset_x=0, offset_y=0, resolution_x=1280, resolution_y=512),\n",
    "              Projection(center_horizontal=180, center_vertical=0, fov_horizontal=82.6, fov_vertical=38.7,\n",
    "                          full_resolution_x=1280, full_resolution_y=512,\n",
    "                          offset_x=0, offset_y=0, resolution_x=1280, resolution_y=512)]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=0, fov_horizontal=82.6, fov_vertical=34.2,\n",
    "                          full_resolution_x=1280, full_resolution_y=384,\n",
    "                          offset_x=0, offset_y=0, resolution_x=1280, resolution_y=384),\n",
    "              Projection(center_horizontal=180, center_vertical=0, fov_horizontal=82.6, fov_vertical=34.2,\n",
    "                          full_resolution_x=1280, full_resolution_y=384,\n",
    "                          offset_x=0, offset_y=0, resolution_x=1280, resolution_y=384)]\n",
    "s_count = s_confidence = 0\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=-2, fov_horizontal=82.6, fov_vertical=29.6,\n",
    "                          full_resolution_x=1280, full_resolution_y=384,\n",
    "                          offset_x=0, offset_y=0, resolution_x=1280, resolution_y=384),\n",
    "               Projection(center_horizontal=180, center_vertical=-2, fov_horizontal=82.6, fov_vertical=29.6,\n",
    "                          full_resolution_x=1280, full_resolution_y=384,\n",
    "                          offset_x=0, offset_y=0, resolution_x=1280, resolution_y=384)]\n",
    "\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=-1, fov_horizontal=82.6, fov_vertical=36.7,\n",
    "                          full_resolution_x=1280, full_resolution_y=384,\n",
    "                          offset_x=0, offset_y=0, resolution_x=1280, resolution_y=384),\n",
    "               Projection(center_horizontal=180, center_vertical=-1, fov_horizontal=82.6, fov_vertical=36.7,\n",
    "                          full_resolution_x=1280, full_resolution_y=384,\n",
    "                          offset_x=0, offset_y=0, resolution_x=1280, resolution_y=384)] # 578.9\n",
    "\"\"\"\n",
    "\n",
    "##################################################\n",
    "# Aplastat\n",
    "\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=-1, fov_horizontal=82.6, fov_vertical=38.7,\n",
    "                          full_resolution_x=1280, full_resolution_y=384,\n",
    "                          offset_x=0, offset_y=0, resolution_x=1280, resolution_y=384),\n",
    "              Projection(center_horizontal=180, center_vertical=-1, fov_horizontal=82.6, fov_vertical=38.7,\n",
    "                          full_resolution_x=1280, full_resolution_y=384,\n",
    "                          offset_x=0, offset_y=0, resolution_x=1280, resolution_y=384)]  # 0.787 1315\n",
    "\n",
    "##################################################\n",
    "# Crop de perspective\n",
    "\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=0, fov_horizontal=82.6, fov_vertical=38.7,\n",
    "                          full_resolution_x=1280, full_resolution_y=512,\n",
    "                          offset_x=0, offset_y=512-384, resolution_x=1280, resolution_y=384),\n",
    "               Projection(center_horizontal=180, center_vertical=0, fov_horizontal=82.6, fov_vertical=38.7,\n",
    "                          full_resolution_x=1280, full_resolution_y=512,\n",
    "                          offset_x=0, offset_y=512-384, resolution_x=1280, resolution_y=384)] # 0.794 1602\n",
    "\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=-1, fov_horizontal=82.6, fov_vertical=38.7,\n",
    "                          full_resolution_x=1280, full_resolution_y=512,\n",
    "                          offset_x=0, offset_y=512-384, resolution_x=1280, resolution_y=384),\n",
    "               Projection(center_horizontal=180, center_vertical=-1, fov_horizontal=82.6, fov_vertical=38.7,\n",
    "                          full_resolution_x=1280, full_resolution_y=512,\n",
    "                          offset_x=0, offset_y=512-384, resolution_x=1280, resolution_y=384)] # 0.789 1671\n",
    "\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=-2, fov_horizontal=82.6, fov_vertical=38.7,\n",
    "                          full_resolution_x=1280, full_resolution_y=512,\n",
    "                          offset_x=0, offset_y=512-384, resolution_x=1280, resolution_y=384),\n",
    "               Projection(center_horizontal=180, center_vertical=-2, fov_horizontal=82.6, fov_vertical=38.7,\n",
    "                          full_resolution_x=1280, full_resolution_y=512,\n",
    "                          offset_x=0, offset_y=512-384, resolution_x=1280, resolution_y=384)] # 0.793 1672\n",
    "\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=-3, fov_horizontal=82.6, fov_vertical=38.7,\n",
    "                          full_resolution_x=1280, full_resolution_y=512,\n",
    "                          offset_x=0, offset_y=512-384, resolution_x=1280, resolution_y=384),\n",
    "               Projection(center_horizontal=180, center_vertical=-3, fov_horizontal=82.6, fov_vertical=38.7,\n",
    "                          full_resolution_x=1280, full_resolution_y=512,\n",
    "                          offset_x=0, offset_y=512-384, resolution_x=1280, resolution_y=384)] # 0.795 1640\n",
    "\n",
    "##################################################\n",
    "# Standard\n",
    "\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=0, fov_horizontal=82.6, fov_vertical=29.6,\n",
    "                          full_resolution_x=1280, full_resolution_y=384,\n",
    "                          offset_x=0, offset_y=0, resolution_x=1280, resolution_y=384),\n",
    "               Projection(center_horizontal=180, center_vertical=0, fov_horizontal=82.6, fov_vertical=29.6,\n",
    "                          full_resolution_x=1280, full_resolution_y=384,\n",
    "                          offset_x=0, offset_y=0, resolution_x=1280, resolution_y=384)] # 0.789 1373\n",
    "\n",
    "##################################################\n",
    "# More height\n",
    "\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=0, fov_horizontal=82.6, fov_vertical=38.7,\n",
    "                          full_resolution_x=1280, full_resolution_y=512,\n",
    "                          offset_x=0, offset_y=0, resolution_x=1280, resolution_y=512),\n",
    "              Projection(center_horizontal=180, center_vertical=0, fov_horizontal=82.6, fov_vertical=38.7,\n",
    "                          full_resolution_x=1280, full_resolution_y=512,\n",
    "                          offset_x=0, offset_y=0, resolution_x=1280, resolution_y=512)] # 0.798 1096\n",
    "\n",
    "##################################################\n",
    "# Looking down\n",
    "\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=-5, fov_horizontal=82.6, fov_vertical=29.6,\n",
    "                          full_resolution_x=1280, full_resolution_y=384,\n",
    "                          offset_x=0, offset_y=0, resolution_x=1280, resolution_y=384),\n",
    "               Projection(center_horizontal=180, center_vertical=-5, fov_horizontal=82.6, fov_vertical=29.6,\n",
    "                          full_resolution_x=1280, full_resolution_y=384,\n",
    "                          offset_x=0, offset_y=0, resolution_x=1280, resolution_y=384)] # 0.796 1603\n",
    "\n",
    "##################################################\n",
    "# Various crops\n",
    "\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=0, fov_horizontal=82.6, fov_vertical=47.5,\n",
    "                          full_resolution_x=1280, full_resolution_y=640,\n",
    "                          offset_x=0, offset_y=640-384, resolution_x=1280, resolution_y=384),\n",
    "               Projection(center_horizontal=180, center_vertical=0, fov_horizontal=82.6, fov_vertical=47.5,\n",
    "                          full_resolution_x=1280, full_resolution_y=640,\n",
    "                          offset_x=0, offset_y=640-384, resolution_x=1280, resolution_y=384)] # 0.793 1414\n",
    "\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=0, fov_horizontal=82.6, fov_vertical=45.3,\n",
    "                          full_resolution_x=1280, full_resolution_y=608,\n",
    "                          offset_x=0, offset_y=608-384, resolution_x=1280, resolution_y=384),\n",
    "               Projection(center_horizontal=180, center_vertical=0, fov_horizontal=82.6, fov_vertical=45.3,\n",
    "                          full_resolution_x=1280, full_resolution_y=608,\n",
    "                          offset_x=0, offset_y=608-384, resolution_x=1280, resolution_y=384)] # 0.796 1575\n",
    "\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=0, fov_horizontal=82.6, fov_vertical=43.14,\n",
    "                          full_resolution_x=1280, full_resolution_y=576,\n",
    "                          offset_x=0, offset_y=576-384, resolution_x=1280, resolution_y=384),\n",
    "               Projection(center_horizontal=180, center_vertical=0, fov_horizontal=82.6, fov_vertical=43.14,\n",
    "                          full_resolution_x=1280, full_resolution_y=576,\n",
    "                          offset_x=0, offset_y=576-384, resolution_x=1280, resolution_y=384)] # 0.794 1658\n",
    "\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=0, fov_horizontal=82.6, fov_vertical=40.95,\n",
    "                          full_resolution_x=1280, full_resolution_y=544,\n",
    "                          offset_x=0, offset_y=544-384, resolution_x=1280, resolution_y=384),\n",
    "               Projection(center_horizontal=180, center_vertical=0, fov_horizontal=82.6, fov_vertical=40.95,\n",
    "                          full_resolution_x=1280, full_resolution_y=544,\n",
    "                          offset_x=0, offset_y=544-384, resolution_x=1280, resolution_y=384)] # 0.792 1655\n",
    "\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=0, fov_horizontal=82.6, fov_vertical=36.5,\n",
    "                          full_resolution_x=1280, full_resolution_y=480,\n",
    "                          offset_x=0, offset_y=480-384, resolution_x=1280, resolution_y=384),\n",
    "               Projection(center_horizontal=180, center_vertical=0, fov_horizontal=82.6, fov_vertical=36.5,\n",
    "                          full_resolution_x=1280, full_resolution_y=480,\n",
    "                          offset_x=0, offset_y=480-384, resolution_x=1280, resolution_y=384)] # 0.796 1554\n",
    "\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=-1, fov_horizontal=82.6, fov_vertical=40.95,\n",
    "                          full_resolution_x=1280, full_resolution_y=544,\n",
    "                          offset_x=0, offset_y=544-384, resolution_x=1280, resolution_y=384),\n",
    "               Projection(center_horizontal=180, center_vertical=-1, fov_horizontal=82.6, fov_vertical=40.95,\n",
    "                          full_resolution_x=1280, full_resolution_y=544,\n",
    "                          offset_x=0, offset_y=544-384, resolution_x=1280, resolution_y=384)] # 0.792 1685\n",
    "\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=-2, fov_horizontal=82.6, fov_vertical=40.95,\n",
    "                          full_resolution_x=1280, full_resolution_y=544,\n",
    "                          offset_x=0, offset_y=544-384, resolution_x=1280, resolution_y=384),\n",
    "               Projection(center_horizontal=180, center_vertical=-2, fov_horizontal=82.6, fov_vertical=40.95,\n",
    "                          full_resolution_x=1280, full_resolution_y=544,\n",
    "                          offset_x=0, offset_y=544-384, resolution_x=1280, resolution_y=384)] # 0.794 1640\n",
    "\n",
    "#############\n",
    "# Final\n",
    "\n",
    "PROJECTIONS = [Projection(center_horizontal=0, center_vertical=-1, fov_horizontal=82.6, fov_vertical=40.95,\n",
    "                          full_resolution_x=1280, full_resolution_y=544,\n",
    "                          offset_x=0, offset_y=544-384, resolution_x=1280, resolution_y=384),\n",
    "               Projection(center_horizontal=180, center_vertical=-1, fov_horizontal=82.6, fov_vertical=40.95,\n",
    "                          full_resolution_x=1280, full_resolution_y=544,\n",
    "                          offset_x=0, offset_y=544-384, resolution_x=1280, resolution_y=384)] # 0.792 1685\n",
    "\n",
    "MIN_LAT, MAX_LAT = 41.35, 41.5\n",
    "MIN_LON, MAX_LON = 2.1, 2.3\n",
    "PLOT = True\n",
    "LOG = False\n",
    "\n",
    "s_count = s_confidence = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "266fd2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StreetView initializations\n",
    "main_kluster = Kluster(session=MongoClient(*MONGO_SESSION_ARGS))\n",
    "bounding_polygon = [(MIN_LAT, MIN_LON), (MIN_LAT, MAX_LON), (MAX_LAT, MAX_LON),\n",
    "                    (MAX_LAT, MIN_LON), (MIN_LAT, MIN_LON)]\n",
    "bounding_polygon = {\"type\": \"Polygon\", \"coordinates\": [[[lon, lat] for lat, lon in bounding_polygon]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f6be7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DD3D initializations\n",
    "with initialize(config_path=CFG_PATH):\n",
    "    cfg = compose(config_name=CFG_NAME)\n",
    "setup(cfg)\n",
    "dd3d_model = build_model(cfg).eval()\n",
    "Checkpointer(dd3d_model).load(CHECKPOINT)\n",
    "dd3d_predictor = lambda image: process_scene(dd3d_model, image, plot=PLOT, log=LOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a9c5713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load segment_ids of interest\n",
    "ways = main_kluster.fetch_data(\"ways\", {\"path\": {\"$geoIntersects\": {\"$geometry\": bounding_polygon}}})\n",
    "segment_ids = [seg_id for way in ways for seg_id in way[\"segments\"].values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe0063a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentations used: [ResizeShortestEdge(short_edge_length=(384, 384), max_size=100000, sample_style='choice')]\n"
     ]
    }
   ],
   "source": [
    "# Dataset and Loader\n",
    "dataset = PanoramaDataset(MONGO_SESSION_ARGS, segment_ids, PREDICTION_KEYWORD, PROJECTIONS)\n",
    "mapper = ParkinkDatasetMapper(cfg, is_train=False, intrinsics=INTRINSICS, extrinsics=EXTRINSICS)\n",
    "dataset = MapDataset(dataset, mapper)\n",
    "loader = DataLoader(dataset, batch_size=None, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86514248",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inference(main_kluster, dd3d_predictor, loader, PREDICTION_KEYWORD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02595cc",
   "metadata": {},
   "source": [
    "Mapper should match keys `instrinsics`, `width`, `height`, `extrinsics` from \n",
    "{'intrinsics': [612.6, 0.0, 640.0, 0.0, 612.6, 128.0, 0.0, 0.0, 1.0],\n",
    " 'file_name': '/workspace/dd3d/datasets/KITTI3D/inference/image_2/a_back.jpg',\n",
    " 'width': 1280,\n",
    " 'height': 384,\n",
    " 'image_id': 'a_back_camera_2',\n",
    " 'sample_id': 'a_back',\n",
    " 'extrinsics': {'wxyz': [1.0, 0.0, 0.0, 0.0], 'tvec': [0.0, 0.0, 0.0]}}\n",
    "for each projection element in the list.\n",
    "\n",
    "Additionally, it should follow the default mapper logic to obtain the mapped dataset. i.e.\n",
    "{'intrinsics': tensor([[612.6000,   0.0000, 640.0000],\n",
    "        [  0.0000, 612.6000, 128.0000],\n",
    "        [  0.0000,   0.0000,   1.0000]]), 'file_name': '/workspace/dd3d/datasets/KITTI3D/inference/image_2/a_back.jpg', 'width': 1280, 'height': 384, 'image_id': 'a_back_camera_2', 'sample_id': 'a_back', 'extrinsics': wxyz: +1.000 +0.000i +0.000j +0.000k, tvec: ([0.00 0.00 0.00]), 'image': tensor([[[100, 127, 144,  ...,  62,  80,  95],\n",
    "         [106, 120, 126,  ...,  67,  86,  99],\n",
    "         [ 72,  82,  91,  ...,  69,  88, 100],\n",
    "         ...,\n",
    "         [254, 254, 254,  ...,  54,  67,  67],\n",
    "         [254, 254, 254,  ...,  37,  53,  60],\n",
    "         [254, 254, 254,  ...,  14,  32,  42]],\n",
    "\n",
    "        [[120, 147, 164,  ...,  71,  89, 104],\n",
    "         [127, 141, 147,  ...,  76,  95, 108],\n",
    "         [ 94, 104, 113,  ...,  78,  97, 109],\n",
    "         ...,\n",
    "         [254, 254, 254,  ...,  75,  86,  86],\n",
    "         [254, 254, 254,  ...,  58,  71,  78],\n",
    "         [254, 254, 254,  ...,  35,  50,  60]],\n",
    "\n",
    "        [[121, 148, 165,  ...,  75,  93, 108],\n",
    "         [128, 142, 148,  ...,  80,  99, 112],\n",
    "         [ 92, 102, 111,  ...,  82, 101, 113],\n",
    "         ...,\n",
    "         [254, 254, 254,  ...,  72,  83,  83],\n",
    "         [254, 254, 254,  ...,  56,  70,  77],\n",
    "         [254, 254, 254,  ...,  33,  49,  59]]], dtype=torch.uint8), 'inv_intrinsics': tensor([[ 0.0016,  0.0000, -1.0447],\n",
    "        [ 0.0000,  0.0016, -0.2089],\n",
    "        [ 0.0000,  0.0000,  1.0000]])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac669f60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
